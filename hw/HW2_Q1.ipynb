{"cells":[{"cell_type":"markdown","metadata":{"id":"hjRM13EAuL3g"},"source":["# HW2 - Q1: Least Squares Regression (30 points)\n","Notes:\n","* Question (a) needs to be typewritten.\n","* Questions (b), (c), and (d) need to be programmed.\n","* Important:\n","  * Write all the steps of the solution. \n","  * Use proper LATEX formatting and notation for all mathematical equations, vectors, and matrices. \n","* For programming solution:\n","  * Properly add comments to your code.\n","\n","#### <font color=\"red\">A note about notation:</font>\n","The notations in this homework are slightly different from the lecture notes. In lecture, we use notation for data as: $(t_i, y_i)$ with regressor $\\hat{y}=x^\\top t$, $x$ is a vector of unknown coefficients and solve $Ax=b$.\\\n","In this homework, the notation that we use for data is: $(x_i, y_i)$ with regressor $\\hat{y}=\\beta^\\top x$ and $\\beta$ is a vector of unknown coefficients to be solved.\n"]},{"cell_type":"markdown","metadata":{"id":"ZUJgYttwjmpK"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XUycEdJg6hzY"},"source":["### **(a)** Consider a dataset with $m$ datapoints: $(x_i, y_i), i=1,...,m$. Perform the multivariate calculus derivation of the least squares regression formula for an estimation function $ùë¶ÃÇ(ùë•)=ùëéùë•^2+ùëèùë•+ùëê$, where $a,b, \\text{and } c$ are the scalar parameters. (6 points)"]},{"cell_type":"markdown","metadata":{"id":"Fthrg3347BEr"},"source":["#### <font color=\"red\">Your answer here:</font>"]},{"cell_type":"markdown","metadata":{"id":"kcWdWt8F68nR"},"source":["\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"ZAjNXSsJuPDn"},"source":["### **(b)** In this problem, we would like to use a linear regressor to fit the data, where $\\hat{y}(x)=ax+b$ with $a,b,x$ being scalars. Denote $\\beta_{LS} = \\begin{bmatrix} a \\\\ b \\end{bmatrix}$ to contain the regressor coefficients, and recall that the linear algebraic formula for least squares gives $\\beta_{LS} = (A^\\top A)^{-1} A^\\top y$ with $A^\\dagger=(A^\\top A)^{-1} A^\\top$ known as the pseudo-inverse of $A$. \n","\n","### In this problem, we ask you to \n","### **#1.** Use the function `np.linalg.pinv` to find the values of regressor coefficients $\\beta_{LS} $ and match it with your previous result. Note that the following piece of starter code generates a random least squares regression dataset with 500 data-points. \n","\n","\n","### **#2.** Further match your results by directly solving the problem using the builtin numpy function: `np.linalg.lstsq`\n","### **#3.** Plot a graph between $X$ and $y$, and overlay it with the linear regression line. (6 points)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"odrt11XjuEb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X is: (500, 1)\n","Shape of y is: (500,)\n"]}],"source":["### !!! DO NOT EDIT !!!\n","# starter code to generate a random least squares regression dataset with 500 points\n","import numpy as np\n","from scipy import optimize\n","import matplotlib.pyplot as plt\n","from sklearn import datasets\n","\n","# generate x and y\n","X, y =  datasets.make_regression(n_samples=500, n_features=1, n_informative=1, n_targets=1, bias=10, noise=25, random_state=42, coef=False)\n","print('Shape of X is:', X.shape)\n","print('Shape of y is:', y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RImfs6SU5bAs"},"outputs":[],"source":["#######\n","# !!! YOUR CODE HERE !!!\n","\n","#######"]},{"cell_type":"markdown","metadata":{"id":"fmPom4m97CH4"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QjDICRJk7dW3"},"source":["### **(c)** In this problem, we ask you to \n","### **#1.** Write a function `my_func_fit (X,y)`, where `X` and `y` are column vectors of the same size containing experimental data. The function should return the values for $\\alpha$ and $\\beta$ which are the scalar parameters of the estimation function $ùë¶ÃÇ (ùë•)=ùõºùë•^ùõΩ$.\n","### **#2.** Test your code on the generated sample dataset and report the coefficients. The given piece of starter code generates a logarithmic dataset. \n","### **#3.** Plot a graph between $X$ vs $y$, and overlay it with the linear regression line. (8 points)\n","\n","**Linear regression for non-linear estimation function:** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oua89wUM7Bqr"},"outputs":[],"source":["### !!! DO NOT EDIT !!!\n","# starter code to generate a random exponential dataset\n","X = np.linspace(1, 10, 101)\n","y = 2*(X**(0.3)) + 0.3*np.random.random(len(X))\n","print('Shape of X is:', X.shape)\n","print('Shape of y is:', y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xM_yXf_B8YRl"},"outputs":[],"source":["#######\n","# !!! YOUR CODE HERE !!!\n","\n","#######"]},{"cell_type":"markdown","metadata":{"id":"_Yrz5pPQ8yaY"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"n6bBltHe9wM3"},"source":["### **(d)** In this problem, we ask you to \n","\n","### **#1.** Write a function `my_lin_regression(f, X, y)`, where `f` is a list containing function objects to basis functions that are pre-defined, and `X` and `y` are arrays containing noisy data. Assume that `X` and `y` are the same size, i.e, $X^{(i)}\\in \\mathbb{R}, y^{(i)}\\in \\mathbb{R}$. Return an array `beta` which represent the coefficients of the solved problem. I.e. we are solving the $\\beta$ which contains the coefficients in the regressor $ùë¶ÃÇ (ùë•)=ùõΩ_1‚ãÖùëì_1(x)+ùõΩ_2‚ãÖùëì_2(x)+‚ãØ+ùõΩ_n‚ãÖùëì_n(ùë•)$ with $f_i$ being basis functions. \n","\n","### **#2.** Also write a function `regression_plot(f,X,y,beta)` which plots a graph between `X` and `y`, and overlays it with the regression line. A few test scenarios are given to validate your code. (10 points)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kpqckqKv9t5p"},"outputs":[],"source":["#######\n","# !!! YOUR CODE HERE !!!\n","\n","#######"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHIs_4zc8yEP"},"outputs":[],"source":["### !!! DO NOT EDIT !!!\n","### Test-1\n","X = np.linspace(0, 2*np.pi, 1000)\n","y = 3*np.sin(X) - 2*np.cos(X) + np.random.random(len(X))\n","f = [np.sin, np.cos] # f1 = sin, f2 = cos\n","\n","beta = my_lin_regression(f, X, y)\n","regression_plot(f,X,y,beta)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m06AxpFKCrCK"},"outputs":[],"source":["### !!! DO NOT EDIT !!!\n","### Test-2\n","X = np.linspace(0, 1, 1000)\n","y = 2*np.exp(0.5*X) + 0.25*np.random.random(len(X))\n","f = [np.exp] # f1 = exp\n","\n","beta = my_lin_regression(f, X, y)\n","regression_plot(f,X,y,beta)"]},{"cell_type":"markdown","metadata":{"id":"whHiUTe--qKn"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]}],"metadata":{"colab":{"name":"HW2_Q1.ipynb","provenance":[]},"interpreter":{"hash":"0d146b57fee91990d15ae8fc1751d37d08a02ef7f56ec35b0f16c4f321b407cd"},"kernelspec":{"display_name":"Python 3.9.7","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
